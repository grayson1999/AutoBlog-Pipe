"""
AI ì½˜í…ì¸  ìƒì„± ëª¨ë“ˆ
OpenAI APIë¥¼ í™œìš©í•œ ë¸”ë¡œê·¸ ê¸€ ìë™ ìƒì„±
"""

import os
import time
import logging
import json
from pathlib import Path
from typing import Dict, Optional, Any, List

try:
    from openai import OpenAI
    import openai
except ImportError:
    raise ImportError("OpenAI library not found. Install with: pip install openai")

from ..config import Config
from ..research.content_researcher import ContentResearcher
from ..utils.content_deduplicator import ContentDeduplicator

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class ContentGenerator:
    """AI ê¸°ë°˜ ì½˜í…ì¸  ìƒì„±ê¸°"""
    
    def __init__(self, api_key: Optional[str] = None):
        """
        ContentGenerator ì´ˆê¸°í™”
        
        Args:
            api_key (str, optional): OpenAI API í‚¤. Noneì´ë©´ í™˜ê²½ë³€ìˆ˜ì—ì„œ ë¡œë“œ
        """
        self.api_key = api_key or Config.OPENAI_API_KEY
        if not self.api_key:
            raise ValueError("OpenAI API key is required. Set OPENAI_API_KEY environment variable.")
        
        self.client = OpenAI(api_key=self.api_key)
        self.prompts_dir = Config.PROMPTS_DIR

        self.default_model = "gpt-5-mini"
        self.default_max_tokens = 2500
        self.default_temperature = 0.7
        self.max_retries = 3
        self.retry_delay = 1
        
        logger.info("ContentGenerator initialized successfully")

    def generate_post_with_research(self, topic_title: str, category: str = 'Tech', keywords: List[str] = []) -> Optional[str]:
        """ë¦¬ì„œì¹˜ ê¸°ë°˜ìœ¼ë¡œ ë¸”ë¡œê·¸ ê¸€ì„ ìƒì„±í•˜ëŠ” ì „ì²´ íŒŒì´í”„ë¼ì¸"""
        logger.info(f"--- Starting research-based generation for: {topic_title} ---")

        # 1. ì¤‘ë³µ ì²´í¬
        deduplicator = ContentDeduplicator()
        if deduplicator.check_duplicates(topic_title):
            logger.warning(f"Topic '{topic_title}' is a duplicate. Skipping generation.")
            return None

        # 2. ë¦¬ì„œì¹˜ ìˆ˜í–‰
        researcher = ContentResearcher()
        research_data = researcher.research_topic(topic_title)

        if not research_data.get('key_facts') and not research_data.get('recent_developments'):
            logger.error(f"Not enough research data found for '{topic_title}'. Skipping generation.")
            return None

        # 3. í”„ë¡¬í”„íŠ¸ ì¤€ë¹„
        summarized_research = self._summarize_research_data(research_data)

        topic = {
            'title': topic_title,
            'research_data': summarized_research
        }
        
        try:
            template = self.load_prompt_template('researched')
            formatted_prompt = self.format_prompt(template, topic)

            # 4. AI ì½˜í…ì¸  ìƒì„±
            generated_content = self.call_openai_api(formatted_prompt, topic_title=topic_title, summarized_research=summarized_research)

            # 5. í’ˆì§ˆ ê²€ì¦
            if not self.validate_content(generated_content):
                logger.warning("Generated content failed validation, but proceeding...")

            logger.info(f"Successfully generated post with research: {topic_title}")
            return generated_content

        except Exception as e:
            logger.error(f"Failed to generate post with research for topic '{topic_title}': {e}")
            raise

    def _summarize_research_data(self, research_data: Dict[str, Any]) -> str:
        """ë¦¬ì„œì¹˜ ë°ì´í„°ë¥¼ LLMì´ ì´í•´í•˜ê¸° ì‰¬ìš´ ìì—°ì–´ ìš”ì•½ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
        summary_parts = []

        if research_data.get('key_facts'):
            summary_parts.append("Key Facts:")
            for fact in research_data['key_facts']:
                summary_parts.append(f"- {fact}")

        if research_data.get('recent_developments'):
            summary_parts.append("\nRecent Developments:")
            for dev in research_data['recent_developments']:
                title = dev.get('title', 'N/A')
                source = dev.get('source', 'N/A')
                summary_parts.append(f"- {title} (Source: {source})")

        return "\n".join(summary_parts)
    
    def load_prompt_template(self, post_type: str) -> str:
        """í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ íŒŒì¼ ë¡œë“œ"""
        template_file = self.prompts_dir / f"post_{post_type}.txt"
        if not template_file.exists():
            raise FileNotFoundError(f"Prompt template not found: {template_file}")
        
        try:
            with open(template_file, 'r', encoding='utf-8') as f:
                return f.read().strip()
        except Exception as e:
            logger.error(f"Error loading prompt template {post_type}: {e}")
            raise
    
    def format_prompt(self, template: str, topic: Dict[str, Any]) -> str:
        """í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì— ì£¼ì œ ì •ë³´ë¥¼ ì±„ì›Œë„£ì–´ ì‹¤ì œ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        topic_data = {
            'title': topic.get('title', 'ì œëª© ì—†ìŒ'),
            'category': topic.get('category', 'ì¼ë°˜'),
            'keywords': ', '.join(topic.get('keywords', [])),
            'word_count': topic.get('word_count', 800),
            'content': topic.get('content', ''),
            'research_data': topic.get('research_data', '{}')
        }
        
        try:
            return template.format(**topic_data)
        except KeyError as e:
            logger.error(f"Missing template variable: {e}")
            raise ValueError(f"Template formatting failed: missing variable {e}")
    
    def call_openai_api(self, prompt: str, topic_title: str, summarized_research: str,
                        max_tokens: Optional[int] = None, temperature: Optional[float] = None) -> str:
        max_tokens = max_tokens or self.default_max_tokens
        # â­ gpt-5 ê³„ì—´ì—ì„  temperatureë¥¼ ê¸°ë³¸ì ìœ¼ë¡œ ë³´ë‚´ì§€ ì•Šë„ë¡ None ê¶Œì¥
        if self.default_model.startswith("gpt-5"):
            temperature = None

        for attempt in range(self.max_retries):
            try:
                api_kwargs = dict(
                    model=self.default_model,
                    messages=[
                        {"role": "system", "content": (
                            "ë‹¹ì‹ ì€ ì „ë¬¸ ë¸”ë¡œê·¸ ì‘ê°€ì…ë‹ˆë‹¤... (ìƒëµ)\n"
                            f"ì£¼ì œ: {topic_title}\n\në¦¬ì„œì¹˜ ë°ì´í„°:\n{summarized_research}"
                        )},
                        {"role": "user", "content": prompt},
                    ],
                    # âœ… gpt-5 ê³„ì—´: max_tokens â†’ max_completion_tokens
                    max_completion_tokens=max_tokens,
                )
                if temperature is not None:
                    api_kwargs["temperature"] = temperature

                response = self.client.chat.completions.create(**api_kwargs)

                generated_text = response.choices[0].message.content.strip()
                if not generated_text:
                    raise ValueError("Empty response from OpenAI API")
                return generated_text

            except Exception as e:
                msg = str(e)
                # ğŸ” ëª¨ë¸ì´ temperature ë¯¸ì§€ì›ì´ë©´ ì œê±°í•˜ê³  1íšŒ ì¬ì‹œë„
                if "temperature" in msg and "Only the default (1) value is supported" in msg and "temperature" in api_kwargs:
                    api_kwargs.pop("temperature", None)
                    response = self.client.chat.completions.create(**api_kwargs)
                    text = response.choices[0].message.content.strip()
                    if not text:
                        raise ValueError("Empty response from OpenAI API")
                    return text

                logger.error(f"OpenAI API error on attempt {attempt + 1}: {e}")
                if attempt == self.max_retries - 1:
                    raise
                time.sleep(self.retry_delay)

    
    def validate_content(self, content: str, min_length: int = 500) -> bool:
        """ìƒì„±ëœ ì½˜í…ì¸  í’ˆì§ˆ ê²€ì¦"""
        if not content or len(content.strip()) < min_length:
            logger.warning(f"Content too short: {len(content)} characters (minimum: {min_length})")
            return False
        
        if not content.strip().startswith('#'):
            logger.warning("Content doesn't start with proper heading")
            return False
        
        if content.count('\n##') < 2:
            logger.warning(f"Content has too few sections: {content.count('##')}")
            return False
        
        return True
    
    def generate_post(self, topic: Dict[str, Any]) -> str:
        """ì£¼ì œ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë¸”ë¡œê·¸ ê¸€ ìƒì„± (ë ˆê±°ì‹œ)""" # Legacy method
        required_fields = ['title', 'post_type']
        for field in required_fields:
            if field not in topic:
                raise ValueError(f"Missing required field: {field}")
        
        post_type = topic['post_type']
        template = self.load_prompt_template(post_type)
        formatted_prompt = self.format_prompt(template, topic)
        generated_content = self.call_openai_api(formatted_prompt, topic_title=topic['title'], summarized_research="") # summarized_research is not used in legacy mode
        
        if not self.validate_content(generated_content):
            logger.warning("Generated content failed validation, but proceeding...")
        
        return generated_content

def test_generate_post_with_research():
    """ContentGeneratorì˜ ë¦¬ì„œì¹˜ ê¸°ë°˜ ìƒì„± í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    try:
        generator = ContentGenerator()
        content = generator.generate_post_with_research("The Future of Artificial Intelligence")
        
        if content:
            print("Research-based content generation test successful!")
            print(f"Generated content length: {len(content)} characters")
            print("\n--- Generated Content Preview ---")
            print(content[:500] + "...")
        else:
            print("Content generation skipped (likely a duplicate or lack of data).")
        
        return True

    except Exception as e:
        print(f"Research-based content generation test failed: {e}")
        return False

if __name__ == "__main__":
    test_generate_post_with_research()
